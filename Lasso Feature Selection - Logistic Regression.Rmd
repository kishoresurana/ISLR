---
title: "Lasso Feature Selection - Logistic Regression"
author: "Kishore Surana"
date: "June 18, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

https://stats.stackexchange.com/questions/72251/an-example-lasso-regression-using-glmnet-for-binary-outcome


```{r}
library(ISLR)
install.packages("glmnet")
library(glmnet)

age     <- c(4, 8, 7, 12, 6, 9, 10, 14, 7) 
gender  <- as.factor(c(1, 0, 1, 1, 1, 0, 1, 0, 0))
bmi_p   <- c(0.86, 0.45, 0.99, 0.84, 0.85, 0.67, 0.91, 0.29, 0.88) 
m_edu   <- as.factor(c(0, 1, 1, 2, 2, 3, 2, 0, 1))
p_edu   <- as.factor(c(0, 2, 2, 2, 2, 3, 2, 0, 0))
f_color <- as.factor(c("blue", "blue", "yellow", "red", "red", "yellow", 
                       "yellow", "red", "yellow"))
asthma <- c(1, 1, 0, 1, 0, 0, 0, 1, 1)
xfactors <- model.matrix(asthma ~ gender + m_edu + p_edu + f_color )[, -1]
x <- as.matrix(data.frame(age, bmi_p, xfactors))

glmmod <- glmnet(x, y=as.factor(asthma), alpha=1, family="binomial")
plot(glmmod, xvar="lambda", label = TRUE)
glmmod

```

Lets use cross-validation to select lambda

```{r}
cv.glmmod=cv.glmnet(x, y=asthma, alpha = 1)
plot(cv.glmmod)
best.lambda = cv.glmmod$lambda.min
#cv.glmmod$lambda.1se
coef(cv.glmmod, s="lambda.1se")

```

